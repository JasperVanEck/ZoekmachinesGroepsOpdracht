{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Groep Opdracht Week 4 Zoekmachines\n",
    "\n",
    "## Students: Jasper van Eck, Ghislaine, Joris Galema, Lotte\n",
    "## Student IDs: 6228194, 10996087, 11335165, 11269642\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Content<a name='Top'></a>\n",
    "[Import data](#ImportData)\n",
    "\n",
    "[Create the TF Dict](#TFDict)\n",
    "\n",
    "[Create the TF-IDF and Normalize](#TFIDFNorm)\n",
    "\n",
    "[Vectorize Query](#InputQuery)\n",
    "\n",
    "[Results](#Results)\n",
    "\n",
    "- [WordCloud](#WordCloud) Requirement 3\n",
    "- [Interact with Filters](#Filters) Requirements 1, 2, 4 and 5\n",
    "\n",
    "[Cohen's Kappa](#Cohen) Requirement 6\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data<a name='ImportData'></a>"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 6,
=======
   "execution_count": 15,
>>>>>>> 9b5f3545cf3eea48cbc8c151486a7aa75ceb1dca
=======
   "execution_count": 61,
>>>>>>> 58c9550e1616d9abf7d866c28aabc334c6ed5725
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "from elasticsearch import Elasticsearch\n",
    "import nltk\n",
    "import PIL\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual\n",
    "import json\n",
    "from collections import Counter, defaultdict\n",
    "from sklearn import preprocessing\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 7,
=======
   "execution_count": 3,
>>>>>>> 9b5f3545cf3eea48cbc8c151486a7aa75ceb1dca
=======
   "execution_count": 62,
>>>>>>> 58c9550e1616d9abf7d866c28aabc334c6ed5725
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Open & read JSON file\n",
    "#Init empty list for json data to be stored\n",
    "jsonDataReviews = []\n",
    "with open('IMDB_reviews.json') as json_file:\n",
    "    #Loop through lines in json file, each review is on seperate line\n",
    "    for line in json_file:\n",
    "        #Append to the list of json data\n",
    "        jsonDataReviews.append(json.loads(line))\n",
    "\n",
    "#Read the data from the json file\n",
    "dataReviews = pd.DataFrame(jsonDataReviews)\n",
    "\n",
    "#Add Review_id column\n",
    "#Create index range\n",
    "review_id = list(range(len(dataReviews)))\n",
    "#Insert the index range into the DF\n",
    "dataReviews.insert(0,'review_id',review_id,True)\n",
    "#Cast to string from obj\n",
    "dataReviews['review_summary'] = dataReviews['review_summary'].astype(str)\n",
    "dataReviews['review_text'] = dataReviews['review_text'].astype(str)\n",
    "#Cast to int from str\n",
    "dataReviews['rating'] = dataReviews['rating'].astype(int)\n",
    "#Cast to bool from obj\n",
    "dataReviews['is_spoiler'] = dataReviews['is_spoiler'].astype(bool)\n",
    "#Create datetime objects from the review_date string\n",
    "dataReviews['review_date'] = [datetime.strptime(dateString, '%d %B %Y') for dateString in dataReviews['review_date'].values]"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 8,
=======
   "execution_count": 26,
>>>>>>> 9b5f3545cf3eea48cbc8c151486a7aa75ceb1dca
=======
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Open & read TSV file with movie details\n",
    "dataMovies = pd.read_csv('data.tsv', sep='\\t', header=0, dtype={'tconst':str,'titleType':str,\n",
    "                                                                'primaryTitle':str,'OriginalTitle':str,\n",
    "                                                                'isAdult':str,'startYear':str,'endYear':str,\n",
    "                                                                'runtimeMinutes':str,'genres':str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tconst</th>\n",
       "      <th>titleType</th>\n",
       "      <th>primaryTitle</th>\n",
       "      <th>originalTitle</th>\n",
       "      <th>isAdult</th>\n",
       "      <th>startYear</th>\n",
       "      <th>endYear</th>\n",
       "      <th>runtimeMinutes</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12179</th>\n",
       "      <td>tt0012349</td>\n",
       "      <td>movie</td>\n",
       "      <td>The Kid</td>\n",
       "      <td>The Kid</td>\n",
       "      <td>0</td>\n",
       "      <td>1921</td>\n",
       "      <td>\\N</td>\n",
       "      <td>68</td>\n",
       "      <td>\\N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          tconst titleType primaryTitle originalTitle isAdult startYear  \\\n",
       "12179  tt0012349     movie      The Kid       The Kid       0      1921   \n",
       "\n",
       "      endYear runtimeMinutes genres  \n",
       "12179      \\N             68     \\N  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movieTitles = dataMovies[dataMovies['tconst'].isin(dataReviews['movie_id'].values)]\n",
    "movieTitles.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace the movie_id with the movie name\n",
    "movieTitlesInsertList = [movieTitles[movieTitles['tconst']==movie_id]['primaryTitle'].values[0] for movie_id in dataReviews['movie_id'].values]\n",
    "dataReviews.insert(7, 'movie_title', movieTitlesInsertList, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
>>>>>>> 58c9550e1616d9abf7d866c28aabc334c6ed5725
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>review_date</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>is_spoiler</th>\n",
       "      <th>review_text</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_summary</th>\n",
<<<<<<< HEAD
=======
       "      <th>review_text</th>\n",
       "      <th>movie_title</th>\n",
       "      <th>user_id</th>\n",
>>>>>>> 58c9550e1616d9abf7d866c28aabc334c6ed5725
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10 February 2006</td>\n",
       "      <td>tt0111161</td>\n",
       "      <td>ur1898687</td>\n",
       "      <td>True</td>\n",
       "      <td>In its Oscar year, Shawshank Redemption (writt...</td>\n",
       "      <td>10</td>\n",
<<<<<<< HEAD
       "      <td>A classic piece of unforgettable film-making.</td>\n",
=======
       "      <td>2006-02-10</td>\n",
       "      <td>A classic piece of unforgettable film-making.</td>\n",
       "      <td>In its Oscar year, Shawshank Redemption (writt...</td>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>ur1898687</td>\n",
>>>>>>> 58c9550e1616d9abf7d866c28aabc334c6ed5725
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6 September 2000</td>\n",
       "      <td>tt0111161</td>\n",
       "      <td>ur0842118</td>\n",
       "      <td>True</td>\n",
       "      <td>The Shawshank Redemption is without a doubt on...</td>\n",
       "      <td>10</td>\n",
<<<<<<< HEAD
       "      <td>Simply amazing. The best film of the 90's.</td>\n",
=======
       "      <td>2000-09-06</td>\n",
       "      <td>Simply amazing. The best film of the 90's.</td>\n",
       "      <td>The Shawshank Redemption is without a doubt on...</td>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>ur0842118</td>\n",
>>>>>>> 58c9550e1616d9abf7d866c28aabc334c6ed5725
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3 August 2001</td>\n",
       "      <td>tt0111161</td>\n",
       "      <td>ur1285640</td>\n",
       "      <td>True</td>\n",
       "      <td>I believe that this film is the best story eve...</td>\n",
       "      <td>8</td>\n",
<<<<<<< HEAD
       "      <td>The best story ever told on film</td>\n",
=======
       "      <td>2001-08-03</td>\n",
       "      <td>The best story ever told on film</td>\n",
       "      <td>I believe that this film is the best story eve...</td>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>ur1285640</td>\n",
>>>>>>> 58c9550e1616d9abf7d866c28aabc334c6ed5725
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1 September 2002</td>\n",
       "      <td>tt0111161</td>\n",
       "      <td>ur1003471</td>\n",
       "      <td>True</td>\n",
       "      <td>**Yes, there are SPOILERS here**This film has ...</td>\n",
       "      <td>10</td>\n",
<<<<<<< HEAD
       "      <td>Busy dying or busy living?</td>\n",
=======
       "      <td>2002-09-01</td>\n",
       "      <td>Busy dying or busy living?</td>\n",
       "      <td>**Yes, there are SPOILERS here**This film has ...</td>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>ur1003471</td>\n",
>>>>>>> 58c9550e1616d9abf7d866c28aabc334c6ed5725
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>20 May 2004</td>\n",
       "      <td>tt0111161</td>\n",
       "      <td>ur0226855</td>\n",
       "      <td>True</td>\n",
       "      <td>At the heart of this extraordinary movie is a ...</td>\n",
       "      <td>8</td>\n",
<<<<<<< HEAD
       "      <td>Great story, wondrously told and acted</td>\n",
=======
       "      <td>2004-05-20</td>\n",
       "      <td>Great story, wondrously told and acted</td>\n",
       "      <td>At the heart of this extraordinary movie is a ...</td>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>ur0226855</td>\n",
>>>>>>> 58c9550e1616d9abf7d866c28aabc334c6ed5725
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>12 August 2004</td>\n",
       "      <td>tt0111161</td>\n",
       "      <td>ur1532177</td>\n",
       "      <td>True</td>\n",
       "      <td>In recent years the IMDB top 250 movies has ha...</td>\n",
       "      <td>8</td>\n",
<<<<<<< HEAD
       "      <td>Good , But It Is Overrated By Some</td>\n",
=======
       "      <td>2004-08-12</td>\n",
       "      <td>Good , But It Is Overrated By Some</td>\n",
       "      <td>In recent years the IMDB top 250 movies has ha...</td>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>ur1532177</td>\n",
>>>>>>> 58c9550e1616d9abf7d866c28aabc334c6ed5725
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>9 October 2005</td>\n",
       "      <td>tt0111161</td>\n",
       "      <td>ur6574726</td>\n",
       "      <td>True</td>\n",
       "      <td>I have been a fan of this movie for a long tim...</td>\n",
       "      <td>9</td>\n",
<<<<<<< HEAD
       "      <td>This Movie Saved My Life.</td>\n",
=======
       "      <td>2005-10-09</td>\n",
       "      <td>This Movie Saved My Life.</td>\n",
       "      <td>I have been a fan of this movie for a long tim...</td>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>ur6574726</td>\n",
>>>>>>> 58c9550e1616d9abf7d866c28aabc334c6ed5725
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>4 February 2012</td>\n",
       "      <td>tt0111161</td>\n",
       "      <td>ur31182745</td>\n",
       "      <td>True</td>\n",
       "      <td>I made my account on IMDb Just to Rate this mo...</td>\n",
       "      <td>10</td>\n",
<<<<<<< HEAD
       "      <td>Movie you can see 1000 times</td>\n",
=======
       "      <td>2012-02-04</td>\n",
       "      <td>Movie you can see 1000 times</td>\n",
       "      <td>I made my account on IMDb Just to Rate this mo...</td>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>ur31182745</td>\n",
>>>>>>> 58c9550e1616d9abf7d866c28aabc334c6ed5725
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>24 October 2008</td>\n",
       "      <td>tt0111161</td>\n",
       "      <td>ur9871443</td>\n",
       "      <td>True</td>\n",
       "      <td>A friend of mine listed \"The Shawshank Redempt...</td>\n",
       "      <td>10</td>\n",
<<<<<<< HEAD
       "      <td>The Shawshank Redemption</td>\n",
=======
       "      <td>2008-10-24</td>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>A friend of mine listed \"The Shawshank Redempt...</td>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>ur9871443</td>\n",
>>>>>>> 58c9550e1616d9abf7d866c28aabc334c6ed5725
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>30 July 2011</td>\n",
       "      <td>tt0111161</td>\n",
       "      <td>ur2707735</td>\n",
       "      <td>True</td>\n",
       "      <td>Well I guess I'm a little late to the party as...</td>\n",
       "      <td>10</td>\n",
<<<<<<< HEAD
       "      <td>\"I'm a convicted murderer who provides sound f...</td>\n",
=======
       "      <td>2011-07-30</td>\n",
       "      <td>\"I'm a convicted murderer who provides sound f...</td>\n",
       "      <td>Well I guess I'm a little late to the party as...</td>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>ur2707735</td>\n",
>>>>>>> 58c9550e1616d9abf7d866c28aabc334c6ed5725
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
<<<<<<< HEAD
       "   review_id       review_date   movie_id     user_id  is_spoiler  \\\n",
       "0          0  10 February 2006  tt0111161   ur1898687        True   \n",
       "1          1  6 September 2000  tt0111161   ur0842118        True   \n",
       "2          2     3 August 2001  tt0111161   ur1285640        True   \n",
       "3          3  1 September 2002  tt0111161   ur1003471        True   \n",
       "4          4       20 May 2004  tt0111161   ur0226855        True   \n",
       "5          5    12 August 2004  tt0111161   ur1532177        True   \n",
       "6          6    9 October 2005  tt0111161   ur6574726        True   \n",
       "7          7   4 February 2012  tt0111161  ur31182745        True   \n",
       "8          8   24 October 2008  tt0111161   ur9871443        True   \n",
       "9          9      30 July 2011  tt0111161   ur2707735        True   \n",
=======
       "   review_id  is_spoiler   movie_id  rating review_date  \\\n",
       "0          0        True  tt0111161      10  2006-02-10   \n",
       "1          1        True  tt0111161      10  2000-09-06   \n",
       "2          2        True  tt0111161       8  2001-08-03   \n",
       "3          3        True  tt0111161      10  2002-09-01   \n",
       "4          4        True  tt0111161       8  2004-05-20   \n",
       "5          5        True  tt0111161       8  2004-08-12   \n",
       "6          6        True  tt0111161       9  2005-10-09   \n",
       "7          7        True  tt0111161      10  2012-02-04   \n",
       "8          8        True  tt0111161      10  2008-10-24   \n",
       "9          9        True  tt0111161      10  2011-07-30   \n",
>>>>>>> 58c9550e1616d9abf7d866c28aabc334c6ed5725
       "\n",
       "                                         review_text rating  \\\n",
       "0  In its Oscar year, Shawshank Redemption (writt...     10   \n",
       "1  The Shawshank Redemption is without a doubt on...     10   \n",
       "2  I believe that this film is the best story eve...      8   \n",
       "3  **Yes, there are SPOILERS here**This film has ...     10   \n",
       "4  At the heart of this extraordinary movie is a ...      8   \n",
       "5  In recent years the IMDB top 250 movies has ha...      8   \n",
       "6  I have been a fan of this movie for a long tim...      9   \n",
       "7  I made my account on IMDb Just to Rate this mo...     10   \n",
       "8  A friend of mine listed \"The Shawshank Redempt...     10   \n",
       "9  Well I guess I'm a little late to the party as...     10   \n",
       "\n",
<<<<<<< HEAD
       "                                      review_summary  \n",
       "0      A classic piece of unforgettable film-making.  \n",
       "1         Simply amazing. The best film of the 90's.  \n",
       "2                   The best story ever told on film  \n",
       "3                         Busy dying or busy living?  \n",
       "4             Great story, wondrously told and acted  \n",
       "5                 Good , But It Is Overrated By Some  \n",
       "6                          This Movie Saved My Life.  \n",
       "7                       Movie you can see 1000 times  \n",
       "8                           The Shawshank Redemption  \n",
       "9  \"I'm a convicted murderer who provides sound f...  "
      ]
     },
<<<<<<< HEAD
     "execution_count": 8,
=======
     "execution_count": 26,
>>>>>>> 9b5f3545cf3eea48cbc8c151486a7aa75ceb1dca
=======
       "                                         review_text  \\\n",
       "0  In its Oscar year, Shawshank Redemption (writt...   \n",
       "1  The Shawshank Redemption is without a doubt on...   \n",
       "2  I believe that this film is the best story eve...   \n",
       "3  **Yes, there are SPOILERS here**This film has ...   \n",
       "4  At the heart of this extraordinary movie is a ...   \n",
       "5  In recent years the IMDB top 250 movies has ha...   \n",
       "6  I have been a fan of this movie for a long tim...   \n",
       "7  I made my account on IMDb Just to Rate this mo...   \n",
       "8  A friend of mine listed \"The Shawshank Redempt...   \n",
       "9  Well I guess I'm a little late to the party as...   \n",
       "\n",
       "                movie_title     user_id  \n",
       "0  The Shawshank Redemption   ur1898687  \n",
       "1  The Shawshank Redemption   ur0842118  \n",
       "2  The Shawshank Redemption   ur1285640  \n",
       "3  The Shawshank Redemption   ur1003471  \n",
       "4  The Shawshank Redemption   ur0226855  \n",
       "5  The Shawshank Redemption   ur1532177  \n",
       "6  The Shawshank Redemption   ur6574726  \n",
       "7  The Shawshank Redemption  ur31182745  \n",
       "8  The Shawshank Redemption   ur9871443  \n",
       "9  The Shawshank Redemption   ur2707735  "
      ]
     },
     "execution_count": 66,
>>>>>>> 58c9550e1616d9abf7d866c28aabc334c6ed5725
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Example of data\n",
    "dataReviews.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the TF Dict<a name='TFDict'></a>\n",
    "\n",
    "[Top](#Top)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 9,
=======
   "execution_count": 5,
>>>>>>> 9b5f3545cf3eea48cbc8c151486a7aa75ceb1dca
=======
   "execution_count": 67,
>>>>>>> 58c9550e1616d9abf7d866c28aabc334c6ed5725
   "metadata": {},
   "outputs": [],
   "source": [
    "#Init a default dict\n",
    "tfDict = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "#Init Porter Stemmer\n",
    "ps = nltk.stem.PorterStemmer()\n",
    "\n",
    "#Use less reviews to reduce runtimes for testing/practice\n",
    "dataReviewsLess = dataReviews.head(10000).copy()\n",
    "\n",
    "#Retrieve the actual reviews\n",
    "reviewTexts = dataReviewsLess['review_text'].values\n",
    "\n",
    "#Loop through reviews\n",
    "for i in range(len(reviewTexts)):\n",
    "    #Tokenize reviews and lowercase the text\n",
    "    line = re.split('\\W+',reviewTexts[i].lower())\n",
    "    #Loop through tokens in review\n",
    "    for word in line:\n",
    "        #Stem token\n",
    "        stem = ps.stem(word)\n",
    "        #Increment frequency\n",
    "        tfDict[stem][i] += 1\n",
    "\n",
    "#Add in Corpus Frequency, Document Frequency and reposition the frequencies per document\n",
    "tfDictXtra = defaultdict(lambda: defaultdict(int))\n",
    "for word in tfDict:\n",
    "    tfDictXtra[word]['CorpusFreq'] = sum(tfDict[word].values())\n",
    "    tfDictXtra[word]['DocFreq'] = len(tfDict[word])\n",
    "    tfDictXtra[word]['Freq_per_doc'] = tfDict[word]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the TF-IDF and Normalize<a name='TFIDFNorm'></a>\n",
    "\n",
    "[Top](#Top)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 10,
=======
   "execution_count": 6,
>>>>>>> 9b5f3545cf3eea48cbc8c151486a7aa75ceb1dca
=======
   "execution_count": 68,
>>>>>>> 58c9550e1616d9abf7d866c28aabc334c6ed5725
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the total number of reviews/documents\n",
    "totalDocs = len(dataReviewsLess)\n",
    "\n",
    "#Total unique words\n",
    "totalUniqueWords = len(tfDictXtra)\n",
    "\n",
    "#Create np matrix with zeros\n",
    "tfIdf = np.zeros((totalUniqueWords,totalDocs))\n",
    "\n",
    "#Create dataframe of words with index list to get the word position in matrix for future reference\n",
    "wordsIndex = pd.DataFrame(list(tfDictXtra.keys()),columns=['Words'])\n",
    "#Create index range\n",
    "wordID = list(range(totalUniqueWords))\n",
    "#Insert the index range\n",
    "wordsIndex.insert(0,'Index',wordID,True)\n",
    "#Index counter, to keep track of location in word list\n",
    "wordCounter = 0\n",
    "\n",
    "\n",
    "#loop through words in dict\n",
    "for word in tfDictXtra:\n",
    "    #Loop through frequencies of word in a doc from dict; LET OP deze regel geeft soms AttributeError: 'int' object has no attribute 'keys'\n",
    "    #run de vorige cellen dan weer even opnieuw. Dat verhelpt t meestal\n",
    "    dictLoop = list(tfDictXtra[word]['Freq_per_doc'].keys())\n",
    "    for doc in dictLoop:\n",
    "        #Calculate the TF-IDF\n",
    "        tfIdf[wordCounter,doc] = tfDictXtra[word]['Freq_per_doc'][doc]*math.log((totalDocs/(1+tfDictXtra[word]['DocFreq'])))\n",
    "    wordCounter += 1\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 11,
=======
   "execution_count": 7,
>>>>>>> 9b5f3545cf3eea48cbc8c151486a7aa75ceb1dca
=======
   "execution_count": 69,
>>>>>>> 58c9550e1616d9abf7d866c28aabc334c6ed5725
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transpose the tfIdf matrix and normalize, since the normalize works on rows, and we need to normalize the columns\n",
    "tfIdfNorm = preprocessing.normalize(tfIdf.T, norm='l2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorize query<a name='InputQuery'></a>\n",
    "\n",
    "[Top](#Top)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 24,
=======
   "execution_count": 8,
>>>>>>> 9b5f3545cf3eea48cbc8c151486a7aa75ceb1dca
=======
   "execution_count": 70,
>>>>>>> 58c9550e1616d9abf7d866c28aabc334c6ed5725
   "metadata": {},
   "outputs": [],
   "source": [
    "#Starting/test query\n",
    "query = \"Shawshank remdemption interesting cool\"\n",
    "\n",
    "#Create a normalized vector of query\n",
    "def vectorizeQuery(query):\n",
    "    #Create empty base vector for Term Freq\n",
    "    queryVector = np.zeros(totalUniqueWords)\n",
    "    #Tokenize and make lowercase\n",
    "    line = re.split('\\W+',query.lower())\n",
    "    #Loop through words\n",
    "    for word in line:\n",
    "        #Stem each word\n",
    "        stem = ps.stem(word)\n",
    "        #Increase term freq of query term\n",
    "        queryVector[wordsIndex[wordsIndex['Words']==stem]['Index'].values] += 1\n",
    "    \n",
    "    #Create empty base vector for TF-IDF\n",
    "    queryVectorTfIdf = np.zeros(totalUniqueWords)\n",
    "    #Loop through TF vector of query\n",
    "    for i in range(len(queryVector)):\n",
    "        #Act where a term frequency was recorded\n",
    "        if queryVector[i] != 0:\n",
    "            #Determine the which word it was based on the index\n",
    "            word = str(wordsIndex[wordsIndex['Index']==i]['Words'].values)\n",
    "            #Calculate the TF-IDF\n",
    "            queryVectorTfIdf[i] = queryVector[i]*math.log((totalDocs/(1+tfDictXtra[word]['DocFreq'])))\n",
    "    \n",
    "    #Make the TF-IDF vector a unit vector\n",
    "    length = np.sqrt(queryVectorTfIdf.dot(queryVectorTfIdf))\n",
    "    queryVectorNorm = queryVectorTfIdf/length\n",
    "    \n",
    "    #Return the unit vector\n",
    "    return queryVectorNorm\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 25,
=======
   "execution_count": 9,
>>>>>>> 9b5f3545cf3eea48cbc8c151486a7aa75ceb1dca
=======
   "execution_count": 71,
>>>>>>> 58c9550e1616d9abf7d866c28aabc334c6ed5725
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cosine similarity matching\n",
    "def cosineSim(vector, docVector):\n",
    "    #Only dot product needed since vectors are already unit vectors and therefore the lengths are 1\n",
    "    return vector.dot(docVector)#/(length vector * length docVector)\n",
    "    \n",
    "def rankedList(queryVector):\n",
    "    #Create empty score list\n",
    "    scoreList = np.zeros(totalDocs)\n",
    "    #Loop through each doc\n",
    "    for i in range(len(tfIdfNorm)):\n",
    "        #Calculate for each doc the cosine sim. Index of scoreList = review_id\n",
    "        scoreList[i] = cosineSim(queryVector,tfIdfNorm[i])\n",
    "    \n",
    "    #Create new data frame for ranked list based on smaller DF of data\n",
    "    rankedDocList = dataReviewsLess.copy()\n",
    "    #Insert the similarity score for each review\n",
    "    rankedDocList.insert(0,'Score',scoreList,True)\n",
    "    #Sort the review similarity based on the score and return\n",
    "    return rankedDocList.sort_values(by='Score',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The column label 'Score' is not unique.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-75f0ffb90213>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Create the ranking list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mrankings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrankedList\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvectorizeQuery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-25-f724a2c77d4b>\u001b[0m in \u001b[0;36mrankedList\u001b[0;34m(queryVector)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mrankedDocList\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Score'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscoreList\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m#Sort the review similarity based on the score and return\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrankedDocList\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Score'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36msort_values\u001b[0;34m(self, by, axis, ascending, inplace, kind, na_position)\u001b[0m\n\u001b[1;32m   4991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4992\u001b[0m             \u001b[0mby\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mby\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4993\u001b[0;31m             \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4994\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4995\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mascending\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_label_or_level_values\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1795\u001b[0m                     \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1796\u001b[0m                     \u001b[0mlabel_axis_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabel_axis_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1797\u001b[0;31m                     \u001b[0mmulti_message\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmulti_message\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1798\u001b[0m                 )\n\u001b[1;32m   1799\u001b[0m             )\n",
      "\u001b[0;31mValueError\u001b[0m: The column label 'Score' is not unique."
     ]
    }
   ],
=======
   "execution_count": 10,
=======
   "execution_count": 72,
>>>>>>> 58c9550e1616d9abf7d866c28aabc334c6ed5725
   "metadata": {},
   "outputs": [],
>>>>>>> 9b5f3545cf3eea48cbc8c151486a7aa75ceb1dca
   "source": [
    "#Create the ranking list\n",
    "rankings = rankedList(vectorizeQuery(query))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results<a name='Results'></a>\n",
    "\n",
    "[Top](#Top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WordCloud <a name='WordCloud'></a>\n",
    "\n",
    "[Top](#Top)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 20,
=======
   "execution_count": 11,
>>>>>>> 9b5f3545cf3eea48cbc8c151486a7aa75ceb1dca
=======
   "execution_count": 73,
>>>>>>> 58c9550e1616d9abf7d866c28aabc334c6ed5725
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
<<<<<<< HEAD
<<<<<<< HEAD
       "model_id": "351295493a5b4530a53c9321fad1c689",
=======
       "model_id": "35d3755b93a74fb0a1680881d048d35f",
>>>>>>> 9b5f3545cf3eea48cbc8c151486a7aa75ceb1dca
=======
       "model_id": "b712c72d7d4d48309d05e61dd92d233f",
>>>>>>> 58c9550e1616d9abf7d866c28aabc334c6ed5725
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=25, description='k', max=50, min=1), Output()), _dom_classes=('widget-in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dacdb66593954382b210adaee8b7d7be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=5000, description='i', max=10000, min=1), Output()), _dom_classes=('widg…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Source: https://stackoverflow.com/questions/16645799/how-to-create-a-word-cloud-from-a-corpus-in-python\n",
    "stopwords = set(STOPWORDS)\n",
    "\n",
    "def show_wordcloud(data, title = \"WordCloud of Query Results\"):\n",
    "    wordcloud = WordCloud(\n",
    "        background_color='white',\n",
    "        stopwords=stopwords,\n",
    "        max_words=40,\n",
    "        max_font_size=40, \n",
    "        scale=3,\n",
    "        random_state=1 # chosen at random by flipping a coin; it was heads\n",
    "    ).generate(str(data))\n",
    "\n",
    "    fig = plt.figure(1, figsize=(12, 12))\n",
    "    plt.axis('off')\n",
    "    if title: \n",
    "        fig.suptitle(title, fontsize=20)\n",
    "        fig.subplots_adjust(top=2.3)\n",
    "\n",
    "    plt.imshow(wordcloud)\n",
    "    plt.show()\n",
    "\n",
    "@interact\n",
    "def showingWordcloudsOfKRanking(k=(1,50,1)):\n",
    "    show_wordcloud(rankings.head(k)['review_text'])\n",
    "    \n",
    "\n",
    "@interact\n",
    "def showingWordCloudOfOneReview(i=(1,len(dataReviewsLess),1)):\n",
    "    show_wordcloud(dataReviewsLess[dataReviewsLess['review_id']==i]['review_text'].values,'WordCloud of a review')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interact with Filters<a name='Filters'></a>\n",
    "\n",
    "[Top](#Top)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
=======
   "execution_count": 12,
=======
   "execution_count": 86,
>>>>>>> 58c9550e1616d9abf7d866c28aabc334c6ed5725
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0711458697641b08ecb475b5e764d54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(DatePicker(value=Timestamp('2014-01-01 00:00:00'), description='start_date'), DatePicker…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
>>>>>>> 9b5f3545cf3eea48cbc8c151486a7aa75ceb1dca
   "source": [
    "#Function to filter on the variables created by interact widget\n",
    "def showResultsTime(start_date, end_date, AmountResults, AtleastRating, spoiler, movie_title):\n",
    "    start_date = pd.Timestamp(start_date)\n",
    "    end_date = pd.Timestamp(end_date)\n",
    "    if movie_title == 'None':\n",
    "        if spoiler == 'Both':\n",
    "            return rankings[(rankings.review_date > start_date) \n",
    "                        & (rankings.review_date < end_date) \n",
    "                        & (rankings.rating >= AtleastRating)].head(AmountResults)\n",
    "        elif spoiler == 'Yes':\n",
    "            return rankings[(rankings.review_date > start_date) \n",
    "                        & (rankings.review_date < end_date) \n",
    "                        & (rankings.rating >= AtleastRating)\n",
    "                        & (rankings.is_spoiler == True)].head(AmountResults)\n",
    "        elif spoiler == 'No':\n",
    "            return rankings[(rankings.review_date > start_date) \n",
    "                        & (rankings.review_date < end_date) \n",
    "                        & (rankings.rating >= AtleastRating)\n",
    "                        & (rankings.is_spoiler == False)].head(AmountResults)\n",
    "    else:\n",
    "        if spoiler == 'Both':\n",
    "            return rankings[(rankings.review_date > start_date) \n",
    "                        & (rankings.review_date < end_date) \n",
    "                        & (rankings.rating >= AtleastRating)\n",
    "                        & (rankings.movie_title == movie_title)].head(AmountResults)\n",
    "        elif spoiler == 'Yes':\n",
    "            return rankings[(rankings.review_date > start_date) \n",
    "                        & (rankings.review_date < end_date) \n",
    "                        & (rankings.rating >= AtleastRating)\n",
    "                        & (rankings.is_spoiler == True)\n",
    "                        & (rankings.movie_title == movie_title)].head(AmountResults)\n",
    "        elif spoiler == 'No':\n",
    "            return rankings[(rankings.review_date > start_date) \n",
    "                        & (rankings.review_date < end_date) \n",
    "                        & (rankings.rating >= AtleastRating)\n",
    "                        & (rankings.is_spoiler == False)\n",
    "                        & (rankings.movie_title == movie_title)].head(AmountResults)\n",
    "\n",
    "#Sort the movieTitles DF\n",
    "tmp = movieTitles.sort_values(by='primaryTitle')\n",
    "#Prep a list of movie titles for filter\n",
    "titles = ['None']\n",
    "titles.extend(tmp['primaryTitle'].values)\n",
    "#The interact function for faceted search\n",
    "_ = interact(showResultsTime,\n",
    "             start_date=widgets.DatePicker(value=pd.to_datetime('2014-01-01')),\n",
    "             end_date=widgets.DatePicker(value=pd.to_datetime('2019-01-01')),\n",
    "             AmountResults=(10, 100, 10),\n",
    "             AtleastRating=(1,10,1),\n",
    "             spoiler=['Both','Yes','No'],\n",
    "             movie_title=titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cohen's Kappa<a name='Cohen'></a>\n",
    "[Top](#Top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AveragePrecision(ranked_list_of_results, list_of_relevant_objects):\n",
    "    begin = 1/len(list_of_relevant_objects)\n",
    "    count = 0\n",
    "    for i, res in enumerate(ranked_list_of_results):\n",
    "        for j, obj in enumerate(list_of_relevant_objects):\n",
    "            if obj == res:\n",
    "                itera = (j+1) / (i+1)\n",
    "            count = count + itera\n",
    "    return begin * count\n",
    "\n",
    "def PE(data):\n",
    "    '''On input data, return the P(E) (expected agreement).'''\n",
    "    relevant = 0\n",
    "    nonrelevant = 0\n",
    "    # Iterate over the data\n",
    "    for i in data:\n",
    "        for j in i:\n",
    "            \n",
    "            # Top up the relevant documents by one if 1 is encountered\n",
    "            if j == 1:\n",
    "                relevant += 1\n",
    "            # Top up the nonrelevant documents by one if 0 is encountered\n",
    "            if j == 0:\n",
    "                nonrelevant += 1\n",
    "\n",
    "    # Calculates the total of inspected documents for the judges combined\n",
    "    total = len(data)*2\n",
    "\n",
    "    # Calculates the pooled marginals\n",
    "    rel = relevant/total\n",
    "    nonrel = nonrelevant/total\n",
    "\n",
    "    # Calculates the P(E)\n",
    "    P_E = nonrel**2 + rel **2    \n",
    "    return    P_E \n",
    "\n",
    "\n",
    "def kappa(data, P_E):\n",
    "    agree = 0\n",
    "    for i in data:\n",
    "        temp = None\n",
    "        for j in i:\n",
    "            if temp == j:\n",
    "                agree += 1\n",
    "            temp = j\n",
    "    P_A = agree / len(data)\n",
    "    kappa = (P_A - P_E)/(1 - P_E)   \n",
    "    return kappa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
